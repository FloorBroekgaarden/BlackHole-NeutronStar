{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/PostProcessingScripts.py:25: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  matplotlib.rcParams['text.latex.preamble'] = [r'\\boldmath']\n",
      "../Scripts/PostProcessingScripts.py:44: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]\n",
      "../Scripts/PostProcessingScripts.py:45: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  matplotlib.rcParams['text.latex.preamble'] = [r'\\boldmath']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "#Quick fudge to make import from ../Scripts work\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "\n",
    "\n",
    "\n",
    "# used for weighted percentiles.  \n",
    "from PostProcessingScripts import * \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import pesummary\n",
    "from pesummary.io import read\n",
    "print(pesummary.__version__)\n",
    "import h5py\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   code to create csv files with credible intervals possible GWTC-2 BHNS detections\n",
    "To make this original code work, you will have to download the hdf5 files from the GWTC-2 catalog that belongs to https://arxiv.org/abs/2010.14527\n",
    "This script just creates csv files that summarize the credible intervals of interest for the possible BHNS binaries from GWTC-2. It is probably the most easiest to directly use those CSV files. \n",
    "\n",
    "The GWTC-2 data is available from https://dcc.ligo.org/LIGO-P2000223/public "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "allBHNS = ['GW190425', 'GW190814', 'GW190426_152155', 'GW200105_162426', 'GW200115_042309','GW190917_114630' ]\n",
    "\n",
    "BHNSsGWTC2 = ['GW190425', 'GW190814', 'GW190426_152155'] \n",
    "GWTC2b = ['GW200105_162426', 'GW200115_042309']\n",
    "GWTC2_1 = ['GW190917_114630']\n",
    "\n",
    "\n",
    "def obtainGWTC1_MassAndWeight(dirGWTC='/Volumes/Andromeda/GWTC-1_LVK_catalog/GWTC-2_sample_release/', dfCSVname='/Users/floorbroekgaarden/Projects/BlackHole-NeutronStar/csvFiles/GWTC_Quantiles/'):\n",
    "    \n",
    "    print('calculating credible intervals for possible GWTC-2 BHNS systems')\n",
    "    \n",
    "    for ind_BHNS, BHNS_ in enumerate(allBHNS):\n",
    "    \n",
    "        if BHNS_ in BHNSsGWTC2:\n",
    "            print(BHNS_)\n",
    "            BHNS_file = dirGWTC + BHNS_ +'_comoving.h5'\n",
    "            BHNS = h5.File(BHNS_file, 'r')\n",
    "\n",
    "            data = read(BHNS_file)\n",
    "            samples_dict = data.samples_dict\n",
    "            posterior_samples = samples_dict['PublicationSamples']\n",
    "            parameters = sorted(list(posterior_samples.keys()))\n",
    "\n",
    "            mass_1_source = posterior_samples['mass_1_source']\n",
    "            mass_2_source = posterior_samples['mass_2_source']\n",
    "            total_mass_source = posterior_samples['total_mass_source']\n",
    "            chirp_mass_source= posterior_samples['chirp_mass_source']\n",
    "            # our mass ratio is defined the other way around\n",
    "            mass_ratio= 1./posterior_samples['mass_ratio']\n",
    "            print('mass ratios', BHNS_)\n",
    "            print(mass_ratio)\n",
    "            print(mass_1_source/mass_2_source)\n",
    "            \n",
    "\n",
    "\n",
    "        elif BHNS_ in GWTC2b:\n",
    "            GW_ = BHNS_ \n",
    "            print(GW_)\n",
    "            GW_file = '/Volumes/Andromeda/GWTC-1_LVK_catalog/GWTC-2_sample_release/' + GW_ +'_posterior_samples_v2.h5'\n",
    "            GW = h5.File(GW_file, 'r')\n",
    "            print(GW['C01:Combined_PHM_high_spin']['posterior_samples']['mass_1_source'][...].squeeze())\n",
    "\n",
    "            print(GW.keys())\n",
    "#             data = read(GW_file)\n",
    "#             samples_dict = data.samples_dict\n",
    "#             posterior_samples = samples_dict['PublicationSamples']\n",
    "    #             parameters = sorted(list(posterior_samples.keys()))\n",
    "            posterior_samples = GW['C01:Combined_PHM_high_spin']['posterior_samples']\n",
    "            mass_1_source     = posterior_samples['mass_1_source'][...].squeeze()\n",
    "            mass_2_source     = posterior_samples['mass_2_source'][...].squeeze()\n",
    "            total_mass_source = posterior_samples['total_mass_source'][...].squeeze()\n",
    "            chirp_mass_source = posterior_samples['chirp_mass_source'][...].squeeze()\n",
    "\n",
    "            \n",
    "            # mass ratio\n",
    "            mass_ratio = mass_1_source / mass_2_source  # is the same as: posterior_samples['inverted_mass_ratio']\n",
    "            print('mass ratios', BHNS_)\n",
    "            print(mass_ratio)\n",
    "            print(mass_1_source/mass_2_source)\n",
    "                        \n",
    "            \n",
    "\n",
    "\n",
    "        elif BHNS_ in GWTC2_1:\n",
    "            GW_ = BHNS_\n",
    "            print(GW_)\n",
    "            GW_file = '/Volumes/Andromeda/GWTC-1_LVK_catalog/GWTC-2_sample_release/IGWN-GWTC2p1-v1-'+GW_ +'_PEDataRelease.h5'\n",
    "            GW = h5.File(GW_file, 'r')\n",
    "#             print(GW[['PrecessingSpinIMRHM']]['posterior_samples']['mass_1_source'][...].squeeze())\n",
    "\n",
    "            print(GW.keys())\n",
    "#             data = read(GW_file)\n",
    "#             samples_dict = data.samples_dict\n",
    "#             posterior_samples = samples_dict['PublicationSamples']\n",
    "    #             parameters = sorted(list(posterior_samples.keys()))\n",
    "            posterior_samples = GW['PrecessingSpinIMRHM']['posterior_samples']\n",
    "            mass_1_source     = posterior_samples['mass_1_source'][...].squeeze()\n",
    "            mass_2_source     = posterior_samples['mass_2_source'][...].squeeze()\n",
    "            total_mass_source = posterior_samples['total_mass_source'][...].squeeze()\n",
    "            chirp_mass_source = posterior_samples['chirp_mass_source'][...].squeeze()\n",
    "\n",
    "            \n",
    "            # mass ratio\n",
    "            mass_ratio = mass_1_source / mass_2_source  # is the same as: posterior_samples['inverted_mass_ratio']\n",
    "            print('mass ratios', BHNS_)\n",
    "            print(mass_ratio)\n",
    "            print(mass_1_source/mass_2_source)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "        # prepare DataFrame \n",
    "        xvarHeaders = ['mass_1_source', 'mass_2_source', \\\n",
    "                        'total_mass_source', 'chirp_mass_source', 'symmetric_mass_ratio']\n",
    "\n",
    "        xvarUnits = ['Msun', 'Msun', 'Msun', 'Msun', '#']\n",
    "\n",
    "        # quantiles that I want to know\n",
    "        y_quantiles  =          [ 0.005, 0.05,   0.5,    0.95,  0.995]\n",
    "        indexnames   = ['unit', '0.005', '0.05',  '0.5',  '0.95', '0.995']\n",
    "        # nr of rows and columns that will be used:\n",
    "        ncol_var = len(xvarHeaders)   \n",
    "        ncol_Rate_det = 1\n",
    "\n",
    "        nrows = len(y_quantiles) + 1 # +1 for units (see below)\n",
    "        # store variables, and Observed and intrinsic rates for all MSSFR variations:\n",
    "        ncol = ncol_var #* (ncol_MSSFR) # for each MSSFR I want to give quantiles for each xparam \n",
    "        df_placeholder = np.zeros((nrows, ncol)) # will be filled in loop: \n",
    "\n",
    "        headernames=[]\n",
    "        units=[]\n",
    "        for ind_s, ss in enumerate(xvarHeaders):\n",
    "            sss = ss \n",
    "            headernames.append(sss)\n",
    "            units.append(xvarUnits[ind_s])\n",
    "\n",
    "        # store dataFrame with zeros that we will fill on the go:\n",
    "        dfw = pd.DataFrame(data=df_placeholder, columns=headernames, index=indexnames)   \n",
    "        # add units at first row (index=0)\n",
    "        dfw.iloc[0]=units        \n",
    "\n",
    "\n",
    "\n",
    "        # obtain BH and NS masses from combining GW posteriors.\n",
    "        # by definition LIGO gives Most massive and least massive. \n",
    "        xvarlist = [mass_1_source, mass_2_source, total_mass_source, chirp_mass_source, mass_ratio]\n",
    "\n",
    "\n",
    "        # calculate quantiles with bootstrapping (if Nrepeats>1)\n",
    "        for ind_xvar, xvar in enumerate(xvarlist):\n",
    "\n",
    "\n",
    "                # calculate quantiles (credible intervals) from data \n",
    "                xvar_quantiles = weighted_quantile(values=xvar, quantiles=y_quantiles, \\\n",
    "                     sample_weight=np.ones_like(xvar))\n",
    "\n",
    "                dfw_key = xvarHeaders[ind_xvar] \n",
    "                dfw[dfw_key][1:] = xvar_quantiles\n",
    "\n",
    "\n",
    "        dfCSVname_ = dfCSVname + 'CredibleIntervals_' + BHNS_  + '.csv' \n",
    "        dfw.to_csv(dfCSVname_) \n",
    "\n",
    "\n",
    "        print()\n",
    "    print('finished')\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating credible intervals for possible GWTC-2 BHNS systems\n",
      "GW190425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-29  23:04:36 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:04:36 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:04:36 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:04:36 PESummary INFO    : chi_p = 0 for all samples. Treating this as a non-precessing system\n",
      "2021-08-29  23:04:36 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:04:36 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n",
      "2021-08-29  23:04:41 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:04:41 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:04:41 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:04:41 PESummary INFO    : chi_p = 0 for all samples. Treating this as a non-precessing system\n",
      "2021-08-29  23:04:41 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:04:41 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n",
      "2021-08-29  23:04:46 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:04:46 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:04:46 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:04:46 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:04:46 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n",
      "2021-08-29  23:04:50 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:04:50 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:04:50 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:04:50 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:04:51 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n",
      "2021-08-29  23:04:55 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:04:55 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:04:55 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:04:55 PESummary INFO    : chi_p = 0 for all samples. Treating this as a non-precessing system\n",
      "2021-08-29  23:04:55 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:04:55 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n",
      "2021-08-29  23:05:00 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:05:00 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:05:00 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:05:00 PESummary INFO    : chi_p = 0 for all samples. Treating this as a non-precessing system\n",
      "2021-08-29  23:05:00 PESummary INFO    : Skipping remnant calculations as tidal deformability parameters found in the posterior table.\n",
      "2021-08-29  23:05:00 PESummary WARNING : Could not find reference_frequency in input file. Using 20Hz as default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass ratios GW190425\n",
      "[1.02836824 1.26139008 1.1907685  ... 1.51270026 1.18272038\n",
      " 1.33072726]\n",
      "[1.02836824 1.26139008 1.1907685  ... 1.51270026 1.18272038\n",
      " 1.33072726]\n",
      "\n",
      "GW190814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-29  23:05:47 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:05:47 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:05:47 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n",
      "2021-08-29  23:06:07 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2021-08-29  23:06:07 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2021-08-29  23:06:07 PESummary WARNING : Could not find minimum frequency in input file and one was not passed from the command line. Using 20.0Hz as default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass ratios GW190814\n",
      "[9.58651545 9.27642139 9.11610399 ... 8.82864351 8.82074926\n",
      " 8.86890361]\n",
      "[9.58651545 9.27642139 9.11610399 ... 8.82864351 8.82074926\n",
      " 8.86890361]\n",
      "\n",
      "GW190426_152155\n",
      "mass ratios GW190426_152155\n",
      "[3.75097054 4.47442311 3.5266919  ... 2.55547708 5.02951608\n",
      " 4.14227451]\n",
      "[3.75097054 4.47442311 3.5266919  ... 2.55547708 5.02951608\n",
      " 4.14227451]\n",
      "\n",
      "GW200105_162426\n",
      "[8.37598737 8.73262229 8.41748688 ... 8.98889051 9.25655911\n",
      " 9.00633161]\n",
      "<KeysViewHDF5 ['C01:Combined_NSBH_low_spin', 'C01:Combined_PHM_high_spin', 'C01:Combined_PHM_low_spin', 'C01:PhenomNSBH_low_spin', 'C01:PhenomXAS_a1_lessthan_0point5_low_spin', 'C01:PhenomXAS_low_spin', 'C01:PhenomXHM_a1_lessthan_0point5_low_spin', 'C01:PhenomXHM_high_spin', 'C01:PhenomXHM_low_spin', 'C01:PhenomXPHM_high_spin', 'C01:PhenomXPHM_low_spin', 'C01:SEOBNRv4HM_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4HM_high_spin', 'C01:SEOBNRv4HM_low_spin', 'C01:SEOBNRv4NSBH_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4NSBH_low_spin', 'C01:SEOBNRv4PHM_high_spin', 'C01:SEOBNRv4PHM_low_spin', 'C01:SEOBNRv4_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4_low_spin', 'history', 'version']>\n",
      "mass ratios GW200105_162426\n",
      "[4.24733502 4.55552402 4.29777596 ... 4.99510271 4.91558334\n",
      " 4.81811689]\n",
      "[4.24733502 4.55552402 4.29777596 ... 4.99510271 4.91558334\n",
      " 4.81811689]\n",
      "\n",
      "GW200115_042309\n",
      "[4.63391569 5.73221847 6.27705374 ... 4.87480358 6.58584113\n",
      " 7.62977064]\n",
      "<KeysViewHDF5 ['C01:Combined_NSBH_low_spin', 'C01:Combined_PHM_high_spin', 'C01:Combined_PHM_low_spin', 'C01:PhenomNSBH_low_spin', 'C01:PhenomXAS_a1_lessthan_0point5_low_spin', 'C01:PhenomXAS_low_spin', 'C01:PhenomXHM_a1_lessthan_0point5_low_spin', 'C01:PhenomXHM_high_spin', 'C01:PhenomXHM_low_spin', 'C01:PhenomXPHM_high_spin', 'C01:PhenomXPHM_low_spin', 'C01:SEOBNRv4HM_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4HM_high_spin', 'C01:SEOBNRv4HM_low_spin', 'C01:SEOBNRv4NSBH_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4NSBH_low_spin', 'C01:SEOBNRv4PHM_high_spin', 'C01:SEOBNRv4PHM_low_spin', 'C01:SEOBNRv4_a1_lessthan_0point5_low_spin', 'C01:SEOBNRv4_low_spin', 'history', 'version']>\n",
      "mass ratios GW200115_042309\n",
      "[2.82830681 3.85821972 4.65242913 ... 2.95929107 4.77799832\n",
      " 7.07265161]\n",
      "[2.82830681 3.85821972 4.65242913 ... 2.95929107 4.77799832\n",
      " 7.07265161]\n",
      "\n",
      "GW190917_114630\n",
      "<KeysViewHDF5 ['IMRPhenomXPHM', 'IMRPhenomXPHM_comoving', 'PrecessingSpinIMRHM', 'PrecessingSpinIMRHM_comoving', 'SEOBNRv4PHM', 'SEOBNRv4PHM_comoving', 'history', 'version']>\n",
      "mass ratios GW190917_114630\n",
      "[6.4267923  5.57320567 4.9284336  ... 2.6810527  1.60651691\n",
      " 2.48525573]\n",
      "[6.4267923  5.57320567 4.9284336  ... 2.6810527  1.60651691\n",
      " 2.48525573]\n",
      "\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "obtainGWTC1_MassAndWeight(dirGWTC='/Volumes/Andromeda/GWTC-1_LVK_catalog/GWTC-2_sample_release/', \\\n",
    "                          dfCSVname='/Users/floorbroekgaarden/Projects/Github/BlackHole-NeutronStar/csvFiles/GWTC_Quantiles/')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BHNSsGWTC2 = ['GW190425', 'GW190814', 'GW190426_152155'] \n",
    "\n",
    "def obtainGWTC1_MassAndWeight(dirGWTC='/Volumes/Andromeda/GWTC-1_LVK_catalog/GWTC-2_sample_release/', dfCSVname='/Users/floorbroekgaarden/Projects/BlackHole-NeutronStar/csvFiles/GWTC_Quantiles/'):\n",
    "    \n",
    "    print('calculating credible intervals for possible GWTC-2 BHNS systems')\n",
    "    for ind_BHNS, BHNS_ in enumerate(BHNSsGWTC2):\n",
    "        print(BHNS_)\n",
    "        BHNS_file = dirGWTC + BHNS_ +'_comoving.h5'\n",
    "        BHNS = h5.File(BHNS_file, 'r')\n",
    "\n",
    "        data = read(BHNS_file)\n",
    "        samples_dict = data.samples_dict\n",
    "        posterior_samples = samples_dict['PublicationSamples']\n",
    "        parameters = sorted(list(posterior_samples.keys()))\n",
    "\n",
    "        mass_1_source = posterior_samples['mass_1_source']\n",
    "        mass_2_source = posterior_samples['mass_2_source']\n",
    "        total_mass_source = posterior_samples['total_mass_source']\n",
    "        chirp_mass_source= posterior_samples['chirp_mass_source']\n",
    "        # our mass ratio is defined the other way around\n",
    "        symmetric_mass_ratio= 1./posterior_samples['mass_ratio']\n",
    "\n",
    "\n",
    "\n",
    "        # prepare DataFrame \n",
    "        xvarHeaders = ['mass_1_source', 'mass_2_source', \\\n",
    "                        'total_mass_source', 'chirp_mass_source', 'symmetric_mass_ratio']\n",
    "\n",
    "        xvarUnits = ['Msun', 'Msun', 'Msun', 'Msun', '#']\n",
    "\n",
    "        # quantiles that I want to know\n",
    "        y_quantiles  =          [ 0.005, 0.05,   0.5,    0.95,  0.995]\n",
    "        indexnames   = ['unit', '0.005', '0.05',  '0.5',  '0.95', '0.995']\n",
    "        # nr of rows and columns that will be used:\n",
    "        ncol_var = len(xvarHeaders)   \n",
    "        ncol_Rate_det = 1\n",
    "\n",
    "        nrows = len(y_quantiles) + 1 # +1 for units (see below)\n",
    "        # store variables, and Observed and intrinsic rates for all MSSFR variations:\n",
    "        ncol = ncol_var #* (ncol_MSSFR) # for each MSSFR I want to give quantiles for each xparam \n",
    "        df_placeholder = np.zeros((nrows, ncol)) # will be filled in loop: \n",
    "\n",
    "        headernames=[]\n",
    "        units=[]\n",
    "        for ind_s, ss in enumerate(xvarHeaders):\n",
    "            sss = ss \n",
    "            headernames.append(sss)\n",
    "            units.append(xvarUnits[ind_s])\n",
    "\n",
    "        # store dataFrame with zeros that we will fill on the go:\n",
    "        dfw = pd.DataFrame(data=df_placeholder, columns=headernames, index=indexnames)   \n",
    "        # add units at first row (index=0)\n",
    "        dfw.iloc[0]=units        \n",
    "\n",
    "\n",
    "\n",
    "        # obtain BH and NS masses from combining GW posteriors.\n",
    "        # by definition LIGO gives Most massive and least massive. \n",
    "        xvarlist = [mass_1_source, mass_2_source, total_mass_source, chirp_mass_source, symmetric_mass_ratio]\n",
    "\n",
    "\n",
    "        # calculate quantiles with bootstrapping (if Nrepeats>1)\n",
    "        for ind_xvar, xvar in enumerate(xvarlist):\n",
    "\n",
    "\n",
    "                # calculate quantiles (credible intervals) from data \n",
    "                xvar_quantiles = weighted_quantile(values=xvar, quantiles=y_quantiles, \\\n",
    "                     sample_weight=np.ones_like(xvar))\n",
    "\n",
    "                dfw_key = xvarHeaders[ind_xvar] \n",
    "                dfw[dfw_key][1:] = xvar_quantiles\n",
    "\n",
    "\n",
    "        dfCSVname_ = dfCSVname + 'CredibleIntervals_' + BHNS_  + '.csv' \n",
    "        dfw.to_csv(dfCSVname_) \n",
    "\n",
    "\n",
    "        print()\n",
    "    print('finished')\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
